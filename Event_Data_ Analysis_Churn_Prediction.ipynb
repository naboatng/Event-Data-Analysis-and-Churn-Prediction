{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ed9bd9-915e-4b0e-a13e-c7837c349e23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848c40ad-760e-4656-817b-09c02a5b7adc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b611e13a-ef1b-4f22-a7c7-c6d295aab8b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 15:41:49,109 - INFO - \u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "2024-11-13 15:41:49,109 - INFO - \u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "2024-11-13 15:41:49,147 - INFO -  * Restarting with watchdog (fsevents)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nana/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 15, in <module>\n",
      "    from ipykernel import kernelapp as app\n",
      "  File \"/Users/nana/anaconda3/lib/python3.11/site-packages/ipykernel/__init__.py\", line 5, in <module>\n",
      "    from .connect import *  # noqa\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nana/anaconda3/lib/python3.11/site-packages/ipykernel/connect.py\", line 11, in <module>\n",
      "    import jupyter_client\n",
      "  File \"/Users/nana/anaconda3/lib/python3.11/site-packages/jupyter_client/__init__.py\", line 8, in <module>\n",
      "    from .asynchronous import AsyncKernelClient  # noqa\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nana/anaconda3/lib/python3.11/site-packages/jupyter_client/asynchronous/__init__.py\", line 1, in <module>\n",
      "    from .client import AsyncKernelClient  # noqa\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nana/anaconda3/lib/python3.11/site-packages/jupyter_client/asynchronous/client.py\", line 8, in <module>\n",
      "    from jupyter_client.client import KernelClient\n",
      "  File \"/Users/nana/anaconda3/lib/python3.11/site-packages/jupyter_client/client.py\", line 22, in <module>\n",
      "    from .connect import ConnectionFileMixin\n",
      "  File \"/Users/nana/anaconda3/lib/python3.11/site-packages/jupyter_client/connect.py\", line 27, in <module>\n",
      "    from jupyter_core.paths import jupyter_data_dir\n",
      "  File \"/Users/nana/anaconda3/lib/python3.11/site-packages/jupyter_core/paths.py\", line 19, in <module>\n",
      "    from pathlib import Path\n",
      "  File \"/Users/nana/anaconda3/lib/python3.11/site-packages/pathlib.py\", line 10, in <module>\n",
      "    from collections import Sequence\n",
      "ImportError: cannot import name 'Sequence' from 'collections' (/Users/nana/anaconda3/lib/python3.11/collections/__init__.py)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nana/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import time\n",
    "import logging\n",
    "from psycopg2.extras import execute_values\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from flask import Flask, request, send_file, jsonify\n",
    "import os\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# File processing function\n",
    "def processing_file(file_path, sheet_name=None):\n",
    "    try:\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "        logging.info(\"File loaded successfully. Here's a preview:\")\n",
    "        print(df.head())\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"The file {file_path} was not found.\")\n",
    "    except ValueError as e:\n",
    "        logging.error(f\"ValueError: {e}. Check if the file has accessible sheets and data.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\")\n",
    "\n",
    "# Database connection function\n",
    "def connect_to_db(retries=5, delay=1):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            conn = psycopg2.connect(\n",
    "                dbname=\"postgres\",\n",
    "                user=\"nana\",\n",
    "                password=\"Twin@2017\",\n",
    "                host=\"localhost\",\n",
    "                port=\"5432\"\n",
    "            )\n",
    "            conn.autocommit = True\n",
    "            return conn\n",
    "        except psycopg2.OperationalError as e:\n",
    "            if attempt < retries - 1:\n",
    "                logging.warning(f\"Database connection failed; retrying in {delay} seconds... ({attempt+1}/5)\")\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                logging.error(\"Could not connect to the database.\")\n",
    "                raise\n",
    "\n",
    "# Data insertion function to PostgreSQL\n",
    "def insert_data(events_data):\n",
    "    required_columns = {'user_id', 'event_type', 'event_properties', 'timestamp'}\n",
    "    if not required_columns.issubset(events_data.columns):\n",
    "        logging.error(\"Data does not contain the required columns.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        conn = connect_to_db()\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS events_data (\n",
    "                user_id TEXT,\n",
    "                event_type TEXT,\n",
    "                event_properties TEXT,\n",
    "                timestamp TIMESTAMP\n",
    "            )\n",
    "        ''')\n",
    "\n",
    "        data_to_insert = [(row['user_id'], row['event_type'], row['event_properties'], row['timestamp'])\n",
    "                          for _, row in events_data.iterrows()]\n",
    "\n",
    "        insert_query = '''\n",
    "            INSERT INTO events_data (user_id, event_type, event_properties, timestamp)\n",
    "            VALUES %s\n",
    "        '''\n",
    "        execute_values(cursor, insert_query, data_to_insert)\n",
    "        logging.info(\"Data inserted successfully.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to insert data: {e}\")\n",
    "    finally:\n",
    "        if cursor is not None:\n",
    "            cursor.close()\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "\n",
    "# Function to export DataFrame to Excel\n",
    "def export_results_to_excel(df, output_file):\n",
    "    try:\n",
    "        df.to_excel(output_file, index=False)\n",
    "        logging.info(f'Results exported to {output_file}')\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to export results: {e}\")\n",
    "\n",
    "# Machine learning pipeline\n",
    "def train_and_evaluate(events_data):\n",
    "    # Assuming 'churn' column exists or has been added to events_data\n",
    "    if 'churn' in events_data.columns:\n",
    "        label_encoder = LabelEncoder()\n",
    "        events_data['event_type_encoded'] = label_encoder.fit_transform(events_data['event_type'])\n",
    "\n",
    "        # Ensure 'timestamp' column is in datetime format\n",
    "        events_data['timestamp'] = pd.to_datetime(events_data['timestamp'], errors='coerce')\n",
    "\n",
    "        # Extracting features from timestamp\n",
    "        events_data['hour'] = events_data['timestamp'].dt.hour\n",
    "        events_data['day'] = events_data['timestamp'].dt.day\n",
    "        events_data['month'] = events_data['timestamp'].dt.month\n",
    "\n",
    "        # Features and target\n",
    "        X = events_data[['event_type_encoded', 'hour', 'day', 'month']].copy()\n",
    "        y = events_data['churn']\n",
    "\n",
    "        # Train/test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Random Forest model\n",
    "        clf = RandomForestClassifier(n_estimators=100)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Predict and evaluate\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        logging.info(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "    else:\n",
    "        logging.warning(\"'churn' column is missing; please add it based on churn criteria.\")\n",
    "\n",
    "# Flask application for file upload and results export\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Ensure the 'uploads' directory exists\n",
    "UPLOAD_FOLDER = 'uploads'\n",
    "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
    "\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload_file():\n",
    "    file = request.files.get('file')\n",
    "    if not file:\n",
    "        return jsonify({\"error\": \"No file provided\"}), 400\n",
    "\n",
    "    file_path = os.path.join(UPLOAD_FOLDER, file.filename)\n",
    "    file.save(file_path)\n",
    "\n",
    "    # Process the uploaded Excel file\n",
    "    events_data = processing_file(file_path, sheet_name='events')\n",
    "    if events_data is None:\n",
    "        return jsonify({\"error\": \"File processing failed\"}), 500\n",
    "\n",
    "    # Perform data processing and export results\n",
    "    export_results_to_excel(events_data, 'results.xlsx')\n",
    "\n",
    "    # Ensure results file exists before sending\n",
    "    if not os.path.exists('results.xlsx'):\n",
    "        return jsonify({\"error\": \"Results file not found\"}), 500\n",
    "\n",
    "    return send_file('results.xlsx', as_attachment=True, mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n",
    "\n",
    "# Cohort analysis\n",
    "def create_cohort_analysis(events_data):\n",
    "    events_data['timestamp'] = pd.to_datetime(events_data['timestamp'], errors='coerce')\n",
    "\n",
    "    # Create cohort DataFrame\n",
    "    cohort_df = events_data.groupby('user_id').agg({\n",
    "        'event_type': 'count', \n",
    "        'timestamp': 'min'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Convert 'timestamp' to cohort by month\n",
    "    cohort_df['cohort'] = cohort_df['timestamp'].dt.to_period('M')\n",
    "    print(cohort_df)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    # Load and process the file\n",
    "    file_path = '/Users/nana/Downloads/events_data.xlsx'\n",
    "    events_data = processing_file(file_path, sheet_name='events')\n",
    "\n",
    "    if events_data is not None:\n",
    "        insert_data(events_data)\n",
    "        train_and_evaluate(events_data)\n",
    "        create_cohort_analysis(events_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eaf030-b9ff-4f22-8a9c-26dd7d59a1e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
